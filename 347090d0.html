<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>Python爬虫入门首选，Requests+正则/Xpath | 爱爬虫与大数据 | 张凯恒的个人博客</title><meta name="keywords" content="CIT,爬虫"><meta name="author" content="Kit,2514154656@qq.com"><meta name="copyright" content="Kit"><meta name="format-detection" content="telephone=no"><meta name="theme-color" content="#ffffff"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><meta name="description" content="Python爬虫入门首选，Requests+正则&#x2F;Xpath  学习完Python基本知识，我们就可以正式步入Python 爬虫的大门。 学习爬虫，最基础的便是模拟浏览器向服务器发出请求，那么我们需要从什么地方做起呢？请求需要我们自己来构造吗？需要关心请求这个数据结构的实现吗？需要了解 HTTP、TCP、IP 层的网络传输通信吗？需要知道服务器的响应和应答原理吗？ 可能你无从下手，不过不用担心，P"><meta property="og:type" content="article"><meta property="og:title" content="Python爬虫入门首选，Requests+正则&#x2F;Xpath"><meta property="og:url" content="https://zhangkh.top/347090d0.html"><meta property="og:site_name" content="爱爬虫与大数据 | 张凯恒的个人博客"><meta property="og:description" content="Python爬虫入门首选，Requests+正则&#x2F;Xpath  学习完Python基本知识，我们就可以正式步入Python 爬虫的大门。 学习爬虫，最基础的便是模拟浏览器向服务器发出请求，那么我们需要从什么地方做起呢？请求需要我们自己来构造吗？需要关心请求这个数据结构的实现吗？需要了解 HTTP、TCP、IP 层的网络传输通信吗？需要知道服务器的响应和应答原理吗？ 可能你无从下手，不过不用担心，P"><meta property="og:locale" content="zh_CN"><meta property="og:image" content="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210109214518.png"><meta property="article:published_time" content="2021-01-10T12:05:37.000Z"><meta property="article:modified_time" content="2021-01-10T12:05:37.000Z"><meta property="article:author" content="Kit"><meta property="article:tag" content="CIT"><meta property="article:tag" content="爬虫"><meta name="twitter:card" content="summary"><meta name="twitter:image" content="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210109214518.png"><link rel="shortcut icon" href="/image/favicon.png"><link rel="canonical" href="https://zhangkh.top/347090d0"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="//hm.baidu.com"><link rel="preconnect" href="//busuanzi.ibruce.info"><link rel="preconnect" href="//zz.bdstatic.com"><meta name="google-site-verification" content="nllQIoMhQY7qK9OXRj5jBS7hY_E1NTFKgwUnweEMocA"><meta name="msvalidate.01" content="3161CBC3D35860A692B93E8CE8036933"><meta name="baidu-site-verification" content="code-khCjBXiLy9"><meta name="360-site-verification" content="32c1cf13644221a5eadaf4c16ea331a1"><link rel="manifest" href="/image/pwaicons/manifest.json"><meta name="msapplication-TileColor" content="#fff"><link rel="apple-touch-icon" sizes="180x180" href="/image/pwaicons/apple-touch-icon.png"><link rel="icon" type="image/png" sizes="32x32" href="/image/pwaicons/32.png"><link rel="icon" type="image/png" sizes="16x16" href="/image/pwaicons/16.png"><link rel="mask-icon" href="/image/pwaicons/safari-pinned-tab.svg" color="#5bbad5"><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free/css/all.min.css" media="print" onload='this.media="all"'><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css" media="print" onload='this.media="all"'><script>var _hmt=_hmt||[];!function(){var e=document.createElement("script");e.src="https://hm.baidu.com/hm.js?49ea0cccf823d8608c6f8a12b538e5c3";var t=document.getElementsByTagName("script")[0];t.parentNode.insertBefore(e,t)}()</script><script>var GLOBAL_CONFIG={root:"/",algolia:void 0,localSearch:{path:"search.xml",languages:{hits_empty:"找不到您查询的内容：${query}"}},translate:{defaultEncoding:2,translateDelay:0,msgToTraditionalChinese:"繁",msgToSimplifiedChinese:"简"},noticeOutdate:void 0,highlight:{plugin:"highlighjs",highlightCopy:!0,highlightLang:!0},copy:{success:"复制成功",error:"复制错误",noSupport:"浏览器不支持"},relativeDate:{homepage:!1,post:!1},runtime:"天",date_suffix:{just:"刚刚",min:"分钟前",hour:"小时前",day:"天前",month:"个月前"},copyright:{limitCount:50,languages:{author:"作者: Kit",link:"链接: ",source:"来源: 爱爬虫与大数据 | 张凯恒的个人博客",info:"著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。"}},lightbox:"fancybox",Snackbar:{chs_to_cht:"你已切换为繁体",cht_to_chs:"你已切换为简体",day_to_night:"你已切换为深色模式",night_to_day:"你已切换为浅色模式",bgLight:"#49b1f5",bgDark:"#2d3035",position:"bottom-left"},source:{jQuery:"https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js",justifiedGallery:{js:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/js/jquery.justifiedGallery.min.js",css:"https://cdn.jsdelivr.net/npm/justifiedGallery/dist/css/justifiedGallery.min.css"},fancybox:{js:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js",css:"https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"}},isPhotoFigcaption:!1,islazyload:!0,isanchor:!0},saveToLocal={set:function(t,e,i){const n=864e5*i,s={value:e,expiry:(new Date).getTime()+n};localStorage.setItem(t,JSON.stringify(s))},get:function(t){const e=localStorage.getItem(t);if(!e)return;const i=JSON.parse(e);if(!((new Date).getTime()>i.expiry))return i.value;localStorage.removeItem(t)}};const getScript=t=>new Promise((e,i)=>{const n=document.createElement("script");n.src=t,n.async=!0,n.onerror=i,n.onload=n.onreadystatechange=function(){const t=this.readyState;t&&"loaded"!==t&&"complete"!==t||(n.onload=n.onreadystatechange=null,e())},document.head.appendChild(n)})</script><script id="config_change">var GLOBAL_CONFIG_SITE={isPost:!0,isHome:!1,isHighlightShrink:!1,isToc:!0,postUpdate:"2021-01-10 20:05:37"}</script><noscript><style>#nav{opacity:1}.justified-gallery img{opacity:1}#post-meta time,#recent-posts time{display:inline!important}</style></noscript><script>!function(){window.activateDarkMode=function(){document.documentElement.setAttribute("data-theme","dark"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#0d0d0d")},window.activateLightMode=function(){document.documentElement.setAttribute("data-theme","light"),null!==document.querySelector('meta[name="theme-color"]')&&document.querySelector('meta[name="theme-color"]').setAttribute("content","#ffffff")};const e=saveToLocal.get("theme");"dark"===e?activateDarkMode():"light"===e&&activateLightMode();const t=saveToLocal.get("aside-status");void 0!==t&&("hide"===t?document.documentElement.classList.add("hide-aside"):document.documentElement.classList.remove("hide-aside"));const o=saveToLocal.get("global-font-size");void 0!==o&&document.documentElement.style.setProperty("--global-font-size",o+"px")}()</script><style>.app-refresh{position:fixed;top:-2.2rem;left:0;right:0;z-index:99999;padding:0 1rem;font-size:15px;height:2.2rem;transition:all .3s ease}.app-refresh-wrap{display:flex;color:#fff;height:100%;align-items:center;justify-content:center}.app-refresh-wrap a{color:#fff;text-decoration:underline;cursor:pointer}</style><link rel="stylesheet" href="//at.alicdn.com/t/font_2296420_0542xp5i00pe.css"><meta name="generator" content="Hexo 5.3.0"><link rel="alternate" href="/atom.xml" title="爱爬虫与大数据 | 张凯恒的个人博客" type="application/atom+xml"></head><body><div id="sidebar"><div id="menu-mask"></div><div id="sidebar-menus"><div class="author-avatar"><img class="avatar-img" data-lazy-src="/image/avatar.png" onerror='onerror=null,src="/img/friend_404.gif"' alt="avatar"></div><div class="site-data"><div class="data-item is-center"><div class="data-item-link"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/tags/"><div class="headline">标签</div><div class="length-num">29</div></a></div></div><div class="data-item is-center"><div class="data-item-link"><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/f58e0e38.html"><i class="fa-fw fas fa-folder-open"></i> <span>资源分享</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>时间轴</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa fa-heartbeat"></i> <span>清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i> <span>音乐</span></a></li><li><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i> <span>照片</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div></div></div></div><div class="post" id="body-wrap"><header class="post-bg" id="page-header" style="background-image:url(https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210109214518.png)"><nav id="nav"><span id="blog_name"><a id="site-name" href="/">爱爬虫与大数据 | 张凯恒的个人博客</a></span><div id="menus"><div id="search-button"><a class="site-page social-icon search"><i class="fas fa-search fa-fw"></i> <span>搜索</span></a></div><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fas fa-home"></i> <span>首页</span></a></div><div class="menus_item"><a class="site-page" href="/f58e0e38.html"><i class="fa-fw fas fa-folder-open"></i> <span>资源分享</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fas fa-archive"></i> <span>时间轴</span></a></div><div class="menus_item"><a class="site-page" href="javascript:void(0);" rel="external nofollow noreferrer"><i class="fa-fw fa fa-heartbeat"></i> <span>清单</span><i class="fas fa-chevron-down expand"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fas fa-music"></i> <span>音乐</span></a></li><li><a class="site-page" href="/Gallery/"><i class="fa-fw fas fa-images"></i> <span>照片</span></a></li></ul></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fas fa-link"></i> <span>友链</span></a></div></div><div id="toggle-menu"><a class="site-page"><i class="fas fa-bars fa-fw"></i></a></div></div></nav><div id="post-info"><h1 class="post-title">Python爬虫入门首选，Requests+正则/Xpath</h1><div id="post-meta"><div class="meta-firstline"><span class="post-meta-date"><i class="far fa-calendar-alt fa-fw post-meta-icon"></i><span class="post-meta-label">发表于</span><time class="post-meta-date-created" datetime="2021-01-10T12:05:37.000Z" title="发表于 2021-01-10 20:05:37">2021-01-10</time><span class="post-meta-separator">|</span><i class="fas fa-history fa-fw post-meta-icon"></i><span class="post-meta-label">更新于</span><time class="post-meta-date-updated" datetime="2021-01-10T12:05:37.000Z" title="更新于 2021-01-10 20:05:37">2021-01-10</time></span><span class="post-meta-categories"><span class="post-meta-separator">|</span><i class="fas fa-inbox fa-fw post-meta-icon"></i><a class="post-meta-categories" href="/categories/%E7%88%AC%E8%99%AB/">爬虫</a></span></div><div class="meta-secondline"><span class="post-meta-separator">|</span><span class="post-meta-wordcount"><i class="far fa-file-word fa-fw post-meta-icon"></i><span class="post-meta-label">字数总计:</span><span class="word-count">4.2k</span><span class="post-meta-separator">|</span><i class="far fa-clock fa-fw post-meta-icon"></i><span class="post-meta-label">阅读时长:</span><span>17分钟</span></span><span class="post-meta-separator">|</span><span class="post-meta-pv-cv"><i class="far fa-eye fa-fw post-meta-icon"></i><span class="post-meta-label">阅读量:</span><span id="busuanzi_value_page_pv"></span></span></div></div></div></header><main class="layout" id="content-inner"><div id="post"><article class="post-content" id="article-container"><h1 id="Python爬虫入门首选，Requests-正则-Xpath"><a href="#Python爬虫入门首选，Requests-正则-Xpath" class="headerlink" title="Python爬虫入门首选，Requests+正则/Xpath"></a>Python爬虫入门首选，Requests+正则/Xpath</h1><iframe id="pqvE7xEK-1596373719908" src="https://player.bilibili.com/player.html?aid=756043858" allowfullscreen data-mediaembed="bilibili" __idm_id__="291592193" style="box-sizing:border-box;outline:0;margin:0;padding:0;font-weight:400;overflow-wrap:break-word;display:block;width:660px;height:330px"></iframe><p>学习完Python基本知识，我们就可以正式步入Python 爬虫的大门。</p><p>学习爬虫，最基础的便是模拟浏览器向服务器发出请求，那么我们需要从什么地方做起呢？请求需要我们自己来构造吗？需要关心请求这个数据结构的实现吗？需要了解 HTTP、TCP、IP 层的网络传输通信吗？需要知道服务器的响应和应答原理吗？</p><p>可能你无从下手，不过不用担心，Python 的强大之处就是提供了功能齐全的类库来帮助我们完成这些请求。利用 Python 现有的库我们可以非常方便地实现网络请求的模拟，常见的库有 urllib、requests 等。</p><p>拿 requests 这个库来说，有了它，我们只需要关心请求的链接是什么，需要传的参数是什么，以及如何设置可选的参数就好了，不用深入到底层去了解它到底是怎样传输和通信的。有了它，两行代码就可以完成一个请求和响应的处理过程，非常方便地得到网页内容。</p><p>接下来，就让我们用 Python 的 requests 库开始我们的爬虫之旅吧。</p><p><a target="_blank" rel="noopener external nofollow noreferrer" href="https://requests.readthedocs.io/en/master/">Requests官方文档</a> <a target="_blank" rel="noopener external nofollow noreferrer" href="https://requests.readthedocs.io/zh_CN/latest/">中文文档</a></p><h3 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h3><p>首先，requests 库是 Python 的一个第三方库，不是自带的。所以我们需要额外安装（<strong>Anaconda自带丰富库，可跳过此步</strong>）。</p><p>在这之前需要你先安装好 Python3 环境，如 Python 3.8 版本。</p><p>安装好 Python3 之后，我们使用 pip3 即可轻松地安装好 requests 库：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install requests</span><br></pre></td></tr></table></figure><p>由于科学上网的原因，国外的第三方库官方下载龟速，请pip换源建议清华镜像。</p><p>安装完成之后，我们就可以开始我们的网络爬虫之旅了。</p><h3 id="实例引入"><a href="#实例引入" class="headerlink" title="实例引入"></a>实例引入</h3><p>用 Python 写爬虫的第一步就是模拟发起一个请求，把网页的源代码获取下来。</p><p>当我们在浏览器中输入一个 URL 并回车，实际上就是让浏览器帮我们发起一个 GET 类型的 HTTP 请求，浏览器得到源代码后，把它渲染出来就可以看到网页内容了。</p><p>那如果我们想用 requests 来获取源代码，应该怎么办呢？很简单，requests 这个库提供了一个 get 方法，我们调用这个方法，并传入对应的 URL 就能得到网页的源代码。</p><p>比如这里有一个示例网站：<a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhangkaiheng.gitee.io/%EF%BC%8C%E5%85%B6%E5%86%85%E5%AE%B9%E5%A6%82%E4%B8%8B%EF%BC%9A">https://zhangkaiheng.gitee.io/，其内容如下：</a></p><p><img src="/image/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210102221113.png"></p><p>哈哈哈哈哈哈！竟然到了爬自己博客的地步！！！</p><p>第一步当然就是获取它的网页源代码了。</p><p>我们可以用 requests 这个库轻松地完成这个过程，代码的写法是这样的：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;zhangkaiheng.gitee.io&#x2F;&#39;)  </span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">&lt;!DOCTYPE html&gt;</span><br><span class="line">&lt;html lang&#x3D;&quot;zh-CN&quot; data-theme&#x3D;&quot;light&quot;&gt;</span><br><span class="line"></span><br><span class="line">&lt;head&gt;</span><br><span class="line">    &lt;meta charset&#x3D;&quot;UTF-8&quot;&gt;</span><br><span class="line">    &lt;meta http-equiv&#x3D;&quot;X-UA-Compatible&quot; content&#x3D;&quot;IE&#x3D;edge&quot;&gt;</span><br><span class="line">    &lt;meta name&#x3D;&quot;viewport&quot; content&#x3D;&quot;width&#x3D;device-width,initial-scale&#x3D;1&quot;&gt;</span><br><span class="line">    &lt;title&gt;爱爬虫与大数据&lt;&#x2F;title&gt;</span><br><span class="line">    &lt;meta name&#x3D;&quot;keywords&quot; content&#x3D;&quot;爱爬虫与大数据&quot;&gt;</span><br><span class="line">    &lt;meta name&#x3D;&quot;author&quot; content&#x3D;&quot;Kit&quot;&gt;</span><br><span class="line">    &lt;meta name&#x3D;&quot;copyright&quot; content&#x3D;&quot;Kit&quot;&gt;</span><br><span class="line">    ...</span><br><span class="line">&lt;&#x2F;head&gt;</span><br><span class="line"></span><br><span class="line">&lt;body&gt;</span><br><span class="line">    &lt;div id&#x3D;&quot;sidebar&quot;&gt;</span><br><span class="line">        &lt;div id&#x3D;&quot;menu-mask&quot;&gt;&lt;&#x2F;div&gt;</span><br><span class="line">        &lt;div id&#x3D;&quot;sidebar-menus&quot;&gt;</span><br><span class="line">...  </span><br><span class="line">&lt;&#x2F;body&gt;</span><br><span class="line"></span><br><span class="line">&lt;&#x2F;html&gt;</span><br></pre></td></tr></table></figure><p>由于网页内容比较多，这里省略了大部分内容。</p><p>不过看运行结果，我们已经成功获取网页的 HTML 源代码，里面包含了电影的标题、类型、上映时间，等等。把网页源代码获取下来之后，下一步我们把想要的数据提取出来，数据的爬取就完成了。</p><p>这个实例的目的是让你体会一下 requests 这个库能帮我们实现什么功能。我们仅仅用 requests 的 get 方法就成功发起了一个 GET 请求，把网页源代码获取下来了，是不是很方便呢？</p><h3 id="请求"><a href="#请求" class="headerlink" title="请求"></a>请求</h3><p>HTTP 中最常见的请求之一就是 GET 请求，下面我们来详细了解利用 requests 库构建 GET 请求的方法。</p><h4 id="GET-请求"><a href="#GET-请求" class="headerlink" title="GET 请求"></a>GET 请求</h4><p>我们换一个示例网站，其 URL 为 <a target="_blank" rel="noopener external nofollow noreferrer" href="http://httpbin.org/get%EF%BC%8C%E5%A6%82%E6%9E%9C%E5%AE%A2%E6%88%B7%E7%AB%AF%E5%8F%91%E8%B5%B7%E7%9A%84%E6%98%AF">http://httpbin.org/get，如果客户端发起的是</a> GET 请求的话，该网站会判断并返回相应的请求信息，包括 Headers、IP 等。</p><p>我们还是用相同的方法来发起一个 GET 请求，代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;httpbin.org&#x2F;get&#39;)  </span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;&#125;,</span><br><span class="line">  &quot;headers&quot;: &#123;</span><br><span class="line">    &quot;Accept&quot;: &quot;*&#x2F;*&quot;,</span><br><span class="line">    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;,</span><br><span class="line">    &quot;Host&quot;: &quot;httpbin.org&quot;,</span><br><span class="line">    &quot;User-Agent&quot;: &quot;python-requests&#x2F;2.24.0&quot;,</span><br><span class="line">    &quot;X-Amzn-Trace-Id&quot;: &quot;Root&#x3D;1-5ff98684-119fbcba4197a62114bac501&quot;</span><br><span class="line">  &#125;,</span><br><span class="line">  &quot;origin&quot;: &quot;112.32.241.87&quot;,</span><br><span class="line">  &quot;url&quot;: &quot;http:&#x2F;&#x2F;httpbin.org&#x2F;get&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以发现，我们成功发起了 GET 请求，也通过这个网站的返回结果得到了请求所携带的信息，包括 Headers、URL、IP，等等。</p><p>对于 GET 请求，我们知道 URL 后面是可以跟上一些参数的，如果我们现在想添加两个参数，其中 name 是 kit，age 是 25，URL 就可以写成如下内容：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">http:&#x2F;&#x2F;httpbin.org&#x2F;get?name&#x3D;kit&amp;age&#x3D;19</span><br></pre></td></tr></table></figure><p>要构造这个请求链接，是不是要直接写成这样呢？</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;httpbin.org&#x2F;get?name&#x3D;kit&amp;age&#x3D;19&#39;)</span><br></pre></td></tr></table></figure><p>这样也可以，但如果这些参数还需要我们手动拼接，未免有点不人性化。</p><p>一般情况下，这种信息我们利用 params 这个参数就可以直接传递了，示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line"></span><br><span class="line">data &#x3D; &#123;  </span><br><span class="line">    &#39;name&#39;: &#39;kit&#39;,  </span><br><span class="line">    &#39;age&#39;: 19</span><br><span class="line">&#125; </span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;httpbin.org&#x2F;get&#39;, params&#x3D;data)  </span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;</span><br><span class="line">    &quot;age&quot;: &quot;19&quot;, </span><br><span class="line">    &quot;name&quot;: &quot;kit&quot;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;headers&quot;: &#123;</span><br><span class="line">    &quot;Accept&quot;: &quot;*&#x2F;*&quot;, </span><br><span class="line">    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, </span><br><span class="line">    &quot;Host&quot;: &quot;httpbin.org&quot;, </span><br><span class="line">    &quot;User-Agent&quot;: &quot;python-requests&#x2F;2.24.0&quot;, </span><br><span class="line">    &quot;X-Amzn-Trace-Id&quot;: &quot;Root&#x3D;1-5ff99fab-4dc3d0207d4376fd6923f0c4&quot;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;origin&quot;: &quot;112.32.241.87&quot;, </span><br><span class="line">  &quot;url&quot;: &quot;http:&#x2F;&#x2F;httpbin.org&#x2F;get?name&#x3D;kit&amp;age&#x3D;19&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>在这里我们把 URL 参数通过字典的形式传给 get 方法的 params 参数，通过返回信息我们可以判断，请求的链接自动被构造成了：<a target="_blank" rel="noopener external nofollow noreferrer" href="http://httpbin.org/get?name=kit&amp;age=19%EF%BC%8C%E8%BF%99%E6%A0%B7%E6%88%91%E4%BB%AC%E5%B0%B1%E4%B8%8D%E7%94%A8%E5%86%8D%E5%8E%BB%E8%87%AA%E5%B7%B1%E6%9E%84%E9%80%A0">http://httpbin.org/get?name=kit&amp;age=19，这样我们就不用再去自己构造</a> URL 了，非常方便。</p><p>另外，网页的返回类型实际上是 str 类型，但是它很特殊，是 JSON 格式的。所以，如果想直接解析返回结果，得到一个 JSON 格式的数据的话，可以直接调用 json 方法。</p><p>示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;http:&#x2F;&#x2F;httpbin.org&#x2F;get&#39;)  </span><br><span class="line">print(type(r.text))  </span><br><span class="line">print(r.json())  </span><br><span class="line">print(type(r.json()))</span><br></pre></td></tr></table></figure><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &#39;str&#39;&gt;</span><br><span class="line">&#123;&#39;args&#39;: &#123;&#125;, &#39;headers&#39;: &#123;&#39;Accept&#39;: &#39;*&#x2F;*&#39;, &#39;Accept-Encoding&#39;: &#39;gzip, deflate&#39;, &#39;Host&#39;: &#39;httpbin.org&#39;, &#39;User-Agent&#39;: &#39;python-requests&#x2F;2.24.0&#39;, &#39;X-Amzn-Trace-Id&#39;: </span><br><span class="line">&#39;Root&#x3D;1-5ff987e4-1248c4cd04158eed34ca44c5&#39;&#125;, &#39;origin&#39;: &#39;112.32.241.87&#39;, &#39;url&#39;: &#39;http:&#x2F;&#x2F;httpbin.org&#x2F;get&#39;&#125;</span><br><span class="line">&lt;class &#39;dict&#39;&gt;</span><br></pre></td></tr></table></figure><p>可以发现，调用 json 方法，就可以将返回结果是 JSON 格式的字符串转化为字典。</p><p>但需要注意的是，如果返回结果不是 JSON 格式，便会出现解析错误，抛出 json.decoder.JSONDecodeError 异常。</p><h4 id="解析网页"><a href="#解析网页" class="headerlink" title="解析网页"></a>解析网页</h4><p>上面的请求链接返回的是 JSON 形式的字符串，那么如果请求普通的网页，则肯定能获得相应的内容了。下面以本课时最初的实例页面为例，我们再加上一点提取信息的逻辑，将代码完善成如下的样子：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;maoyan.com&#x2F;board&#x2F;4?offset&#x3D;0&#39;)</span><br><span class="line">pattern &#x3D; re.compile(&#39;&lt;p class&#x3D;&quot;name&quot;&gt;&lt;a href&#x3D;&quot;&#x2F;films&#x2F;.*?&gt;(.*?)&lt;&#x2F;a&gt;&#39;, re.S)</span><br><span class="line">titles &#x3D; re.findall(pattern, r.text)</span><br><span class="line">print(titles)</span><br></pre></td></tr></table></figure><p>在这个例子中我们用到了最基础的正则表达式来匹配出所有的标题。关于正则表达式的相关内容，我们会在下一课时详细介绍，这里作为实例来配合讲解。</p><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">[&#39;我不是药神&#39;, &#39;肖申克的救赎&#39;, &#39;绿皮书&#39;, &#39;海上钢琴师&#39;, &#39;哪吒之魔童降世&#39;, &#39;小偷家族&#39;, &#39;霸王别姬&#39;, &#39;美丽人生&#39;, &#39;盗梦空间&#39;, &#39;这个杀手不太冷&#39;]</span><br></pre></td></tr></table></figure><p>我们发现，这里成功提取出了所有的电影标题。一个最基本的抓取和提取流程就完成了。</p><h4 id="添加-headers"><a href="#添加-headers" class="headerlink" title="添加 headers"></a>添加 headers</h4><p>我们知道，在发起一个 HTTP 请求的时候，会有一个请求头 Request Headers，那么这个怎么来设置呢？</p><p>很简单，我们使用 headers 参数就可以完成了。</p><p>在刚才的实例中，实际上我们是没有设置 Request Headers 信息的，如果不设置，某些网站会发现这不是一个正常的浏览器发起的请求，网站可能会返回异常的结果，导致网页抓取失败。</p><p>要添加 Headers 信息，比如我们这里想添加一个 User-Agent 字段，我们可以这么来写：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">headers &#x3D; &#123;</span><br><span class="line">    &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.7.36.5901 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;zhangkaiheng.gitee.io&#x2F;&#39;, headers&#x3D;headers)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>当然，我们可以在 headers 这个参数中任意添加其他的字段信息。</p><h4 id="POST-请求"><a href="#POST-请求" class="headerlink" title="POST 请求"></a>POST 请求</h4><p>前面我们了解了最基本的 GET 请求，另外一种比较常见的请求方式是 POST。使用 requests 实现 POST 请求同样非常简单，示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">data &#x3D; &#123;&#39;name&#39;: &#39;kit&#39;, &#39;age&#39;: &#39;20&#39;&#125;</span><br><span class="line">r &#x3D; requests.post(&quot;http:&#x2F;&#x2F;httpbin.org&#x2F;post&quot;, data&#x3D;data)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>这里还是请求 <a target="_blank" rel="noopener external nofollow noreferrer" href="http://httpbin.org/post%EF%BC%8C%E8%AF%A5%E7%BD%91%E7%AB%99%E5%8F%AF%E4%BB%A5%E5%88%A4%E6%96%AD%E5%A6%82%E6%9E%9C%E8%AF%B7%E6%B1%82%E6%98%AF">http://httpbin.org/post，该网站可以判断如果请求是</a> POST 方式，就把相关请求信息返回。</p><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line">&#123;</span><br><span class="line">  &quot;args&quot;: &#123;&#125;, </span><br><span class="line">  &quot;data&quot;: &quot;&quot;, </span><br><span class="line">  &quot;files&quot;: &#123;&#125;, </span><br><span class="line">  &quot;form&quot;: &#123;</span><br><span class="line">    &quot;age&quot;: &quot;20&quot;, </span><br><span class="line">    &quot;name&quot;: &quot;kit&quot;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;headers&quot;: &#123;</span><br><span class="line">    &quot;Accept&quot;: &quot;*&#x2F;*&quot;, </span><br><span class="line">    &quot;Accept-Encoding&quot;: &quot;gzip, deflate&quot;, </span><br><span class="line">    &quot;Content-Length&quot;: &quot;15&quot;, </span><br><span class="line">    &quot;Content-Type&quot;: &quot;application&#x2F;x-www-form-urlencoded&quot;,         </span><br><span class="line">    &quot;Host&quot;: &quot;httpbin.org&quot;, </span><br><span class="line">    &quot;User-Agent&quot;: &quot;python-requests&#x2F;2.24.0&quot;, </span><br><span class="line">    &quot;X-Amzn-Trace-Id&quot;: &quot;Root&#x3D;1-5ff99ef7-1d4426a80c49df9d31ff3250&quot;</span><br><span class="line">  &#125;, </span><br><span class="line">  &quot;json&quot;: null, </span><br><span class="line">  &quot;origin&quot;: &quot;112.32.241.87&quot;, </span><br><span class="line">  &quot;url&quot;: &quot;http:&#x2F;&#x2F;httpbin.org&#x2F;post&quot;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><p>可以发现，我们成功获得了返回结果，其中 form 部分就是提交的数据，这就证明 POST 请求成功发送了。</p><h3 id="响应"><a href="#响应" class="headerlink" title="响应"></a>响应</h3><p>发送请求后，得到的自然就是响应，即 Response。</p><p>在上面的实例中，我们使用 text 和 content 获取了响应的内容。此外，还有很多属性和方法可以用来获取其他信息，比如状态码、响应头、Cookies 等。示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;zhangkaiheng.gitee.io&#x2F;&#39;)</span><br><span class="line">print(type(r.status_code), r.status_code)</span><br><span class="line">print(type(r.headers), r.headers)</span><br><span class="line">print(type(r.cookies), r.cookies)</span><br><span class="line">print(type(r.url), r.url)</span><br><span class="line">print(type(r.history), r.history)</span><br></pre></td></tr></table></figure><p>这里分别打印输出 status_code 属性得到状态码，输出 headers 属性得到响应头，输出 cookies 属性得到 Cookies，输出 url 属性得到 URL，输出 history 属性得到请求历史。</p><p>运行结果如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt;class &#39;int&#39;&gt; 200</span><br><span class="line">&lt;class &#39;requests.structures.CaseInsensitiveDict&#39;&gt; &#123;&#39;Date&#39;: &#39;Sat, 09 Jan 2021 12:54:40 GMT&#39;, &#39;Content-Type&#39;: &#39;text&#x2F;html&#39;, &#39;Transfer-Encoding&#39;: &#39;chunked&#39;, &#39;Connection&#39;: &#39;keep-alive&#39;, &#39;Server&#39;: &#39;openresty&#x2F;1.13.6.2&#39;, &#39;Last-Modified&#39;: &#39;Mon, 04 Jan 2021 07:53:48 GMT&#39;, &#39;ETag&#39;: &#39;W&#x2F;&quot;5ff2c98c-9df5&quot;&#39;, &#39;Expires&#39;: &#39;Sun, 10 Jan 2021 12:54:40 GMT&#39;, &#39;Cache-Control&#39;: &#39;max-age&#x3D;86400&#39;, &#39;Content-Encoding&#39;: &#39;gzip&#39;&#125;</span><br><span class="line">&lt;class &#39;requests.cookies.RequestsCookieJar&#39;&gt; &lt;RequestsCookieJar[]&gt;</span><br><span class="line">&lt;class &#39;str&#39;&gt; https:&#x2F;&#x2F;zhangkaiheng.gitee.io&#x2F;</span><br><span class="line">&lt;class &#39;list&#39;&gt; []</span><br></pre></td></tr></table></figure><p>可以看到，headers 和 cookies 这两个属性得到的结果分别是 CaseInsensitiveDict 和 RequestsCookieJar 类型。</p><p>我们知道，<a target="_blank" rel="noopener external nofollow noreferrer" href="https://baike.baidu.com/item/HTTP%E7%8A%B6%E6%80%81%E7%A0%81/5053660?fr=aladdin">状态码</a>是用来表示响应状态的，比如返回 200 代表我们得到的响应是没问题的，上面的例子正好输出的结果也是 200，所以我们可以通过判断 Response 的状态码来确认是否爬取成功。</p><p>requests 还提供了一个内置的状态码查询对象 requests.codes，用法示例如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;zhangkaiheng.gitee.io&#x2F;&#39;)</span><br><span class="line">exit() if not r.status_code &#x3D;&#x3D; requests.codes.ok else print(&#39;Request Successfully&#39;)</span><br></pre></td></tr></table></figure><p>这里通过比较返回码和内置的成功的返回码，来保证请求得到了正常响应，输出成功请求的消息，否则程序终止，这里我们用 requests.codes.ok 得到的是成功的状态码 200。</p><p>这样的话，我们就不用再在程序里面写状态码对应的数字了，用字符串表示状态码会显得更加直观。</p><h1 id="爬虫入门首选开刀网站——猫眼电影"><a href="#爬虫入门首选开刀网站——猫眼电影" class="headerlink" title="爬虫入门首选开刀网站——猫眼电影"></a>爬虫入门首选开刀网站——猫眼电影</h1><h2 id="爬虫准备"><a href="#爬虫准备" class="headerlink" title="爬虫准备"></a>爬虫准备</h2><p>猫眼电影是美团旗下的一家集媒体内容、在线购票、用户互动社交、电影衍生品销售等服务的一站式电影互联网平台。2015年6月，猫眼电影覆盖影院超过4000家，这些影院的票房贡献占比超过90%。目前，猫眼占网络购票70%的市场份额，每三张电影票就有一张出自猫眼电影，是影迷下载量较多、使用率较高的电影应用软件。同时，猫眼电影为合作影院和电影制片发行方提供覆盖海量电影消费者的精准营销方案，助力影片票房。</p><p><img src="/image/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210109211910.png"></p><p>运行平台：win10</p><p>Python版本：3.8</p><p>IDE：Pycharm</p><p>浏览器：Chrome</p><p>目标：获取猫眼Top100电影名称、主演、上映时间、评分、封面图片</p><p>如此网站数据看上去都心动，不过猫眼电影也是有反爬机制的，只不过今天我们的入门小打小闹触及不深。</p><h2 id="分析网页"><a href="#分析网页" class="headerlink" title="分析网页"></a>分析网页</h2><p><img src="/image/loading.gif" data-lazy-src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210109214518.png"></p><p>通过F12或者右键选择检查我们发现两个规律：</p><ol><li>要获取的数据有规律的存在网页代码中：如标题在class属性为name的p标签里、主演在class属性为star的p标签里······</li><li>第一页链接offset=0而第二页链接offset=10推测第三页offset=20</li></ol><h2 id="请求网页"><a href="#请求网页" class="headerlink" title="请求网页"></a>请求网页</h2><p>分析完网页我们可以试着模拟浏览器请求网页</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import requests  </span><br><span class="line"></span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;maoyan.com&#x2F;board&#x2F;4?offset&#x3D;0&#39;)  </span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>为了保证爬虫正常，添加请求头</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line"></span><br><span class="line">headers &#x3D; &#123;</span><br><span class="line">  &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.7.36.5901 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;maoyan.com&#x2F;board&#x2F;4?offset&#x3D;0&#39;, headers&#x3D;headers)</span><br><span class="line">print(r.text)</span><br></pre></td></tr></table></figure><p>试着利用最简单的正则获取第一页的标题</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import requests</span><br><span class="line">import re</span><br><span class="line"></span><br><span class="line">headers &#x3D; &#123;</span><br><span class="line">  &#39;User-Agent&#39;: &#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;87.7.36.5901 Safari&#x2F;537.36&#39;</span><br><span class="line">&#125;</span><br><span class="line">r &#x3D; requests.get(&#39;https:&#x2F;&#x2F;maoyan.com&#x2F;board&#x2F;4?offset&#x3D;0&#39;, headers&#x3D;headers)</span><br><span class="line">pattern &#x3D; re.compile(&#39;&lt;p class&#x3D;&quot;name&quot;&gt;&lt;a href&#x3D;&quot;&#x2F;films&#x2F;.*?&gt;(.*?)&lt;&#x2F;a&gt;&#39;, re.S)</span><br><span class="line">titles &#x3D; re.findall(pattern, r.text)</span><br><span class="line">print(titles)</span><br><span class="line"># 运行结果</span><br><span class="line"># [&#39;我不是药神&#39;, &#39;肖申克的救赎&#39;, &#39;绿皮书&#39;, &#39;海上钢琴师&#39;, &#39;哪吒之魔童降世&#39;, &#39;小偷家族&#39;, &#39;霸王别姬&#39;, &#39;美丽人生&#39;, &#39;盗梦空间&#39;, &#39;这个杀手不太冷&#39;]</span><br></pre></td></tr></table></figure><p>针对规律一我们很容易利用正则解析</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"># 主演</span><br><span class="line">star &#x3D; re.findall(re.compile(&#39;&lt;p class&#x3D;&quot;star&quot;&gt;(.*?)&lt;&#x2F;p&gt;&#39;, re.S), r.text)</span><br><span class="line"># 发表时间</span><br><span class="line">releasetime &#x3D; re.findall(re.compile(&#39;&lt;p class&#x3D;&quot;releasetime&quot;&gt;(.*?)&lt;&#x2F;p&gt;&#39;, re.S), r.text)</span><br><span class="line"># 封面链接</span><br><span class="line">img_urls &#x3D; re.findall(re.compile(&#39;&lt;img data-src&#x3D;&quot;(.*?)&quot; alt&#x3D;&quot;.*?&quot; class&#x3D;&quot;board-img&quot; &#x2F;&gt;&#39;, re.S), r.text)</span><br><span class="line"># 排名</span><br><span class="line">top &#x3D; re.findall(re.compile(&#39;&lt;i class&#x3D;&quot;board-index board-index-.*?&quot;&gt;(.*?)&lt;&#x2F;i&gt;&#39;, re.S), r.text)</span><br></pre></td></tr></table></figure><p>不写了。。。看<a target="_blank" rel="noopener external nofollow noreferrer" href="https://www.bilibili.com/video/BV1Kr4y1T7z8/">视频</a>听口述吧代码自己敲别<a target="_blank" rel="noopener external nofollow noreferrer" href="https://github.com/Kit139/maoyan_movies">copyme</a></p></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者:</span> <span class="post-copyright-info"><a href="mailto:2514154656@qq.com" rel="external nofollow noreferrer">Kit</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接:</span> <span class="post-copyright-info"><a href="https://zhangkh.top/347090d0.html">https://zhangkh.top/347090d0.html</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明:</span> <span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="external nofollow noreferrer" target="_blank">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://zhangkh.top" target="_blank">爱爬虫与大数据 | 张凯恒的个人博客</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/CIT/">CIT</a><a class="post-meta__tags" href="/tags/%E7%88%AC%E8%99%AB/">爬虫</a></div><div class="post_share"><div class="social-share" data-image="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210109214518.png" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css" media="print" onload='this.media="all"'><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js" defer></script></div></div><div class="post-reward"><div class="reward-button"><i class="fas fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><a href="/image/weixin_gzh.jpg" target="_blank"><img class="post-qr-code-img" data-lazy-src="/image/weixin_gzh.jpg" alt="微信公众号"></a><div class="post-qr-code-desc">微信公众号</div></li></ul></div></div></div><nav class="pagination-post" id="pagination"><div class="prev-post pull-left"><a href="/d8816516.html"><img class="prev-cover" data-lazy-src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/640" onerror='onerror=null,src="/img/404.jpg"' alt="cover of previous post"><div class="pagination-info"><div class="label">上一篇</div><div class="prev_info">Python爬取股吧评论+情感分析</div></div></a></div><div class="next-post pull-right"><a href="/47109d5a.html"><img class="next-cover" data-lazy-src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210102220412.png" onerror='onerror=null,src="/img/404.jpg"' alt="cover of next post"><div class="pagination-info"><div class="label">下一篇</div><div class="next_info">20210102寒假第一交流会——黑屏见翻车？不！我在检测认真质量</div></div></a></div></nav><div class="relatedPosts"><div class="headline"><i class="fas fa-thumbs-up fa-fw"></i> <span>相关推荐</span></div><div class="relatedPosts-list"><div><a href="/47109d5a.html" title="20210102寒假第一交流会——黑屏见翻车？不！我在检测认真质量"><img class="cover" data-lazy-src="https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210102220412.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-01-02</div><div class="title">20210102寒假第一交流会——黑屏见翻车？不！我在检测认真质量</div></div></a></div><div><a href="/b77c21ed.html" title="系统软件"><img class="cover" data-lazy-src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210315144235513.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-04</div><div class="title">系统软件</div></div></a></div><div><a href="/7c3563b0.html" title="师弟面对近10万数据向我求救，我：你学的Python呢？"><img class="cover" data-lazy-src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210314175411436.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-03-14</div><div class="title">师弟面对近10万数据向我求救，我：你学的Python呢？</div></div></a></div><div><a href="/b1cf8b54.html" title="CIT20201004系统软件"><img class="cover" data-lazy-src="https://gitee.com/cit_k/pictures/raw/master/picture/PE2.d658a63d.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2020-10-04</div><div class="title">CIT20201004系统软件</div></div></a></div><div><a href="/daaed497.html" title="20210124CITPython交流+WebScraper可视化爬虫"><img class="cover" data-lazy-src="https://gitee.com/cit_k/pictures/raw/master/picture/p62697176.webp" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-01-24</div><div class="title">20210124CITPython交流+WebScraper可视化爬虫</div></div></a></div><div><a href="/729dca89.html" title="Pandas网页Table表格型数据爬虫+快代理实战"><img class="cover" data-lazy-src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210117222007162.png" alt="cover"><div class="content is-center"><div class="date"><i class="far fa-calendar-alt fa-fw"></i> 2021-01-17</div><div class="title">Pandas网页Table表格型数据爬虫+快代理实战</div></div></a></div></div></div><hr><div id="post-comment"><div class="comment-head"><div class="comment-headline"><i class="fas fa-comments fa-fw"></i> <span>评论</span></div></div><div class="comment-wrap"><div><div class="vcomment" id="vcomment"></div></div></div></div></div><div class="aside-content" id="aside-content"><div class="card-widget card-info"><div class="card-info-avatar is-center"><img class="avatar-img" data-lazy-src="/image/avatar.png" onerror='this.onerror=null,this.src="/img/friend_404.gif"' alt="avatar"><div class="author-info__name">Kit</div><div class="author-info__description">石大CIT金融学子一枚，兴趣之余学了点前端、Python、爬虫、数据处理、数学建模Matlab、数据库、量化金融等；啥都感兴趣啥都会一点〒▽〒就是不精通；愿不断学习共同进步！(￣︶￣)↗[GO!]</div></div><div class="card-info-data"><div class="card-info-data-item is-center"><a href="/archives/"><div class="headline">文章</div><div class="length-num">37</div></a></div><div class="card-info-data-item is-center"><a href="/tags/"><div class="headline">标签</div><div class="length-num">29</div></a></div><div class="card-info-data-item is-center"><a href="/categories/"><div class="headline">分类</div><div class="length-num">13</div></a></div></div><a class="button--animated" id="card-info-btn" target="_blank" rel="noopener external nofollow noreferrer" href="https://zhangkaiheng.gitee.io/"><i class="fa fa-bookmark"></i><span>加入书签！收藏！永不迷路！</span></a><div class="card-info-social-icons is-center"><a class="social-icon" href="https://github.com/Kit139" rel="external nofollow noreferrer" target="_blank" title="Github"><i class="fab fa-github"></i></a><a class="social-icon" href="https://gitee.com/zhangkaiheng" rel="external nofollow noreferrer" target="_blank" title="Gitee"><i class="iconfont icon-gitee-fill-round"></i></a><a class="social-icon" href="https://space.bilibili.com/475898359" rel="external nofollow noreferrer" target="_blank" title="Bilibili"><i class="iconfont icon-bilibili-fill"></i></a><a class="social-icon" href="mailto:2514154656@qq.com" rel="external nofollow noreferrer" target="_blank" title="Email"><i class="fas fa-envelope"></i></a></div></div><div class="card-widget card-announcement"><div class="item-headline"><i class="fas fa-bullhorn card-announcement-animation"></i><span>公告</span></div><div class="announcement_content">张凯恒的个人博客——现已建立博客-云盘资源分享-公众号系统一体化</div></div><div class="sticky_layout"><div class="card-widget" id="card-toc"><div class="item-headline"><i class="fas fa-stream"></i><span>目录</span></div><div class="toc-content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E9%A6%96%E9%80%89%EF%BC%8CRequests-%E6%AD%A3%E5%88%99-Xpath"><span class="toc-text">Python爬虫入门首选，Requests+正则&#x2F;Xpath</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%89%E8%A3%85"><span class="toc-text">安装</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AE%9E%E4%BE%8B%E5%BC%95%E5%85%A5"><span class="toc-text">实例引入</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%AF%B7%E6%B1%82"><span class="toc-text">请求</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#GET-%E8%AF%B7%E6%B1%82"><span class="toc-text">GET 请求</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E8%A7%A3%E6%9E%90%E7%BD%91%E9%A1%B5"><span class="toc-text">解析网页</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%B7%BB%E5%8A%A0-headers"><span class="toc-text">添加 headers</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#POST-%E8%AF%B7%E6%B1%82"><span class="toc-text">POST 请求</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%93%8D%E5%BA%94"><span class="toc-text">响应</span></a></li></ol></li></ol><li class="toc-item toc-level-1"><a class="toc-link" href="#%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%E9%A6%96%E9%80%89%E5%BC%80%E5%88%80%E7%BD%91%E7%AB%99%E2%80%94%E2%80%94%E7%8C%AB%E7%9C%BC%E7%94%B5%E5%BD%B1"><span class="toc-text">爬虫入门首选开刀网站——猫眼电影</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#%E7%88%AC%E8%99%AB%E5%87%86%E5%A4%87"><span class="toc-text">爬虫准备</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E5%88%86%E6%9E%90%E7%BD%91%E9%A1%B5"><span class="toc-text">分析网页</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#%E8%AF%B7%E6%B1%82%E7%BD%91%E9%A1%B5"><span class="toc-text">请求网页</span></a></li></ol></li></div></div><div class="card-widget card-recent-post"><div class="item-headline"><i class="fas fa-history"></i><span>最新文章</span></div><div class="aside-list"><div class="aside-list-item"><a class="thumbnail" href="/1659fa3e.html" title="Smallpdf1.24.2win安装包与无限期试用安装教程"><img data-lazy-src="https://gitee.com/cit_k/pictures/raw/master/picture/142104hyyqrp3wzfwqvuqw.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="Smallpdf1.24.2win安装包与无限期试用安装教程"></a><div class="content"><a class="title" href="/1659fa3e.html" title="Smallpdf1.24.2win安装包与无限期试用安装教程">Smallpdf1.24.2win安装包与无限期试用安装教程</a><time datetime="2021-10-07T02:40:20.166Z" title="发表于 2021-10-07 10:40:20">2021-10-07</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/a0c0ece2.html" title="服务兵团，助力连队两委换届"><img data-lazy-src="https://gitee.com/cit_k/pictures/raw/master/picture/1huvshlgxlbsp.jpg" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="服务兵团，助力连队两委换届"></a><div class="content"><a class="title" href="/a0c0ece2.html" title="服务兵团，助力连队两委换届">服务兵团，助力连队两委换届</a><time datetime="2021-07-16T12:05:37.000Z" title="发表于 2021-07-16 20:05:37">2021-07-16</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/a138b51e.html" title="红酒市场需求线上购买需求度调研可视化"><img data-lazy-src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210326012940155.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="红酒市场需求线上购买需求度调研可视化"></a><div class="content"><a class="title" href="/a138b51e.html" title="红酒市场需求线上购买需求度调研可视化">红酒市场需求线上购买需求度调研可视化</a><time datetime="2021-03-26T12:05:37.000Z" title="发表于 2021-03-26 20:05:37">2021-03-26</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/7c3563b0.html" title="师弟面对近10万数据向我求救，我：你学的Python呢？"><img data-lazy-src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210314175411436.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="师弟面对近10万数据向我求救，我：你学的Python呢？"></a><div class="content"><a class="title" href="/7c3563b0.html" title="师弟面对近10万数据向我求救，我：你学的Python呢？">师弟面对近10万数据向我求救，我：你学的Python呢？</a><time datetime="2021-03-14T10:05:37.000Z" title="发表于 2021-03-14 18:05:37">2021-03-14</time></div></div><div class="aside-list-item"><a class="thumbnail" href="/f50b5182.html" title="MagicBook (Pro)修改CFG-Lock和DVMT 64M数值的方法"><img data-lazy-src="https://gitee.com/cit_k/pictures/raw/master/picture/image-20210313184924032.png" onerror='this.onerror=null,this.src="/img/404.jpg"' alt="MagicBook (Pro)修改CFG-Lock和DVMT 64M数值的方法"></a><div class="content"><a class="title" href="/f50b5182.html" title="MagicBook (Pro)修改CFG-Lock和DVMT 64M数值的方法">MagicBook (Pro)修改CFG-Lock和DVMT 64M数值的方法</a><time datetime="2021-03-13T12:05:37.000Z" title="发表于 2021-03-13 20:05:37">2021-03-13</time></div></div></div></div></div></div></main><footer id="footer" style="background-image:url(https://cdn.jsdelivr.net/gh/CIT-K/pictures/picture/20210109214518.png)"><div id="footer-wrap"><div class="copyright">&copy;2020 - 2021 By Kit</div><div class="footer_custom_text">Hi, welcome to my personal blog —— <a target="_blank" rel="noopener external nofollow noreferrer" href="https://zhangkaiheng.gitee.io/">LoveSpider</a>!</div></div></footer></div><div id="rightside"><div id="rightside-config-hide"><button id="readmode" type="button" title="阅读模式"><i class="fas fa-book-open"></i></button><button id="font-plus" type="button" title="放大字体"><i class="fas fa-plus"></i></button><button id="font-minus" type="button" title="缩小字体"><i class="fas fa-minus"></i></button><button id="translateLink" type="button" title="简繁转换">繁</button><button id="darkmode" type="button" title="浅色和深色模式转换"><i class="fas fa-adjust"></i></button><button id="hide-aside-btn" type="button" title="单栏和双栏切换"><i class="fas fa-arrows-alt-h"></i></button></div><div id="rightside-config-show"><button id="rightside_config" type="button" title="设置"><i class="fas fa-cog fa-spin"></i></button><button class="close" id="mobile-toc-button" type="button" title="目录"><i class="fas fa-list-ul"></i></button><button id="chat_btn" type="button" title="rightside.chat_btn"><i class="fas fa-sms"></i></button><a id="to_comment" href="#post-comment" title="直达评论"><i class="fas fa-comments"></i></a><button id="go-up" type="button" title="回到顶部"><i class="fas fa-arrow-up"></i></button></div></div><div id="local-search"><div class="search-dialog"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章" type="text"></div></div></div><hr><div id="local-search-results"></div><span class="search-close-button"><i class="fas fa-times"></i></span></div><div id="search-mask"></div></div><div><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/vanilla-lazyload/dist/lazyload.iife.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script>function panguFn(){"object"==typeof pangu?pangu.spacingElementById("content-inner"):getScript("https://cdn.jsdelivr.net/npm/pangu/dist/browser/pangu.min.js").then(()=>{pangu.spacingElementById("content-inner")})}function panguInit(){GLOBAL_CONFIG_SITE.isPost&&panguFn()}document.addEventListener("DOMContentLoaded",panguInit)</script><script src="/js/search/local-search.js"></script><div class="js-pjax"><script>function loadValine(){function e(){let e={el:"#vcomment",appId:"qz3wb0JS4Pd6cW1H8s96lQ0n-gzGzoHsz",appKey:"CbraUUy5NOeQ3Be7fekLXRqy",placeholder:"记得留下你的昵称和邮箱....可以快速收到回复",avatar:"monsterid",meta:"nick,mail,link".split(","),pageSize:"10",lang:"zh_CN",recordIP:!1,serverURLs:"",emojiCDN:"",emojiMaps:"",enableQQ:!1,path:window.location.pathname};e.requiredFields="nick,mail".split(",");new Valine(e)}"function"==typeof Valine?e():getScript("https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js").then(e)}{function loadOtherComment(){loadValine()}btf.loadComment(document.getElementById("vcomment"),loadValine)}</script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script></div><div class="app-refresh" id="app-refresh"><div class="app-refresh-wrap"><label>✨ 网站已更新最新版本 👉</label> <a href="javascript:void(0)" rel="external nofollow noreferrer" onclick="location.reload()">点击刷新</a></div></div><script>function showNotification(){if(GLOBAL_CONFIG.Snackbar){var t="light"===document.documentElement.getAttribute("data-theme")?GLOBAL_CONFIG.Snackbar.bgLight:GLOBAL_CONFIG.Snackbar.bgDark,e=GLOBAL_CONFIG.Snackbar.position;Snackbar.show({text:"已更新最新版本",backgroundColor:t,duration:5e5,pos:e,actionText:"点击刷新",actionTextColor:"#fff",onActionClick:function(t){location.reload()}})}else{var o=`top: 0; background: ${"light"===document.documentElement.getAttribute("data-theme")?"#49b1f5":"#1f1f1f"};`;document.getElementById("app-refresh").style.cssText=o}}"serviceWorker"in navigator&&(navigator.serviceWorker.controller&&navigator.serviceWorker.addEventListener("controllerchange",(function(){showNotification()})),window.addEventListener("load",(function(){navigator.serviceWorker.register("/sw.js")})))</script><script defer id="ribbon" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-ribbon.min.js" size="150" alpha="0.6" zindex="-1" mobile="false" data-click="true"></script><script id="canvas_nest" defer color="0,0,255" opacity="0.7" zindex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/canvas-nest.min.js"></script><script src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/activate-power-mode.min.js"></script><script>POWERMODE.colorful=!0,POWERMODE.shake=!0,POWERMODE.mobile=!1,document.body.addEventListener("input",POWERMODE)</script><script id="click-heart" src="https://cdn.jsdelivr.net/npm/butterfly-extsrc@1/dist/click-heart.min.js" async mobile="false"></script><script src="https://cdn.jsdelivr.net/npm/pjax/pjax.min.js"></script><script>let pjaxSelectors=["title","#config_change","#body-wrap","#rightside-config-hide","#rightside-config-show",".js-pjax"];var pjax=new Pjax({elements:'a:not([target="_blank"]):not([href="/music/"]):not([href="/no-pjax/"])',selectors:pjaxSelectors,cacheBust:!1,analytics:!1,scrollRestoration:!1});document.addEventListener("pjax:complete",(function(){window.refreshFn(),document.querySelectorAll("script[data-pjax]").forEach(e=>{const t=document.createElement("script"),n=e.text||e.textContent||e.innerHTML||"";Array.from(e.attributes).forEach(e=>t.setAttribute(e.name,e.value)),t.appendChild(document.createTextNode(n)),e.parentNode.replaceChild(t,e)}),GLOBAL_CONFIG.islazyload&&window.lazyLoadInstance.update(),"function"==typeof chatBtnFn&&chatBtnFn(),"function"==typeof panguInit&&panguInit(),"function"==typeof gtag&&gtag("config","",{page_path:window.location.pathname}),"function"==typeof loadMeting&&document.getElementsByClassName("aplayer").length&&loadMeting(),"object"==typeof Prism&&Prism.highlightAll(),"object"==typeof preloader&&preloader.endLoading()})),document.addEventListener("pjax:send",(function(){if("object"==typeof preloader&&preloader.initLoading(),window.aplayers)for(let e=0;e<window.aplayers.length;e++)window.aplayers[e].options.fixed||window.aplayers[e].destroy();"object"==typeof typed&&typed.destroy();const e=document.body.classList;e.contains("read-mode")&&e.remove("read-mode")}))</script><script>!function(){const t=document.createElement("script"),s=window.location.protocol.split(":")[0];t.src="https"===s?"https://zz.bdstatic.com/linksubmit/push.js":"http://push.zhanzhang.baidu.com/push.js",t.dataset.pjax="";const e=document.getElementsByTagName("script")[0];e.parentNode.insertBefore(t,e)}()</script></div></body></html>